{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccb9b81e",
   "metadata": {},
   "source": [
    "# Step 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72e4995",
   "metadata": {},
   "source": [
    "**Cell 1: Imports and Paths Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# CSV path (already includes png_path column)\n",
    "csv_path = r\"C:\\Users\\yasha\\Downloads\\ProjectEXH02\\dataset\\clean_train_data.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e023946b",
   "metadata": {},
   "source": [
    "**Cell 2: Load CSV & Basic Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bdc7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Drop any missing values (important for clean training)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encode categorical values\n",
    "df['Sex'] = df['Sex'].map({'Male': 0, 'Female': 1})\n",
    "df['SmokingStatus'] = df['SmokingStatus'].map({\n",
    "    'Never smoked': 0,\n",
    "    'Ex-smoker': 1,\n",
    "    'Currently smokes': 2\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6be0be",
   "metadata": {},
   "source": [
    "**Cell 3: Select Features & Normalize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to use for tabular model\n",
    "tabular_features = ['Age', 'Sex', 'SmokingStatus', 'Weeks']\n",
    "target = 'FVC'\n",
    "\n",
    "# Scale tabular data\n",
    "scaler = StandardScaler()\n",
    "X_tabular = scaler.fit_transform(df[tabular_features])\n",
    "y_target = df[target].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e37ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Save scaler for test processing)\n",
    "import joblib\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0cd39c",
   "metadata": {},
   "source": [
    "**Cell 4: Define Custom Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b2def",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FVCMixedDataset(Dataset):\n",
    "    def __init__(self, df, tabular_data, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tabular_data = tabular_data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row['png_path']).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        tabular = torch.tensor(self.tabular_data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(row['FVC'], dtype=torch.float32)\n",
    "\n",
    "        return image, tabular, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8f1a5",
   "metadata": {},
   "source": [
    "**Cell 5: Data Split, Transform & Loaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a814a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation split\n",
    "train_df, val_df, train_tab, val_tab = train_test_split(df, X_tabular, test_size=0.2, random_state=42)\n",
    "\n",
    "# Image transformation\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Dataset & DataLoader\n",
    "train_dataset = FVCMixedDataset(train_df, train_tab, transform=image_transform)\n",
    "val_dataset = FVCMixedDataset(val_df, val_tab, transform=image_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9060cc45",
   "metadata": {},
   "source": [
    "**sample CT scan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fc16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check of one batch\n",
    "data_iter = iter(train_loader)\n",
    "images, tabular, labels = next(data_iter)\n",
    "\n",
    "print(f\"Image batch shape      : {images.shape}\")\n",
    "print(f\"Tabular batch shape    : {tabular.shape}\")\n",
    "print(f\"Label batch shape      : {labels.shape}\")\n",
    "\n",
    "# Optional: check one sample\n",
    "print(\"\\nSingle sample values:\")\n",
    "print(f\"Tabular features (0th sample): {tabular[0]}\")\n",
    "print(f\"FVC label (0th sample)       : {labels[0]}\")\n",
    "\n",
    "# Check image as a visual (optional if you're in Jupyter)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(images[0].permute(1, 2, 0).numpy() * 0.5 + 0.5)  # unnormalize for viewing\n",
    "plt.title(f\"FVC: {labels[0].item():.2f}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f672f1bd",
   "metadata": {},
   "source": [
    "# Step 2: Building and Training the Multimodal FVC Prediction Model with MobileNetV3_Large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a249cb97",
   "metadata": {},
   "source": [
    "**Cell 1: Imports, Device Setup, and Seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dd1d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6651902",
   "metadata": {},
   "source": [
    "**Cell 2: Define the Multimodal Model (Image + Tabular MLP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5da186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FVCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FVCNet, self).__init__()\n",
    "        \n",
    "        # MobileNetV3-Large for image branch\n",
    "        self.cnn = models.mobilenet_v3_large(pretrained=True)\n",
    "        self.cnn.classifier[3] = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.cnn.classifier[3].in_features, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Tabular branch\n",
    "        self.tabular_net = nn.Sequential(\n",
    "            nn.Linear(4, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Combined head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 + 16, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),   # Extra dropout for robustness\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, tabular):\n",
    "        img_feat = self.cnn(image)\n",
    "        tab_feat = self.tabular_net(tabular)\n",
    "        combined = torch.cat((img_feat, tab_feat), dim=1)\n",
    "        # Use view(-1) to ensure output shape is [batch_size]\n",
    "        return self.fc(combined).view(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dea53b3",
   "metadata": {},
   "source": [
    "**Cell 3: Initialize Model, Loss Function, Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed813101",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FVCNet().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22124d4",
   "metadata": {},
   "source": [
    "**Cell 4: Training and Evaluation Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c948765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    true_vals = []\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for images, tabulars, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            tabulars = tabulars.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images, tabulars).view(-1)\n",
    "            true_vals.extend(labels.cpu().numpy())\n",
    "            preds.extend(outputs.cpu().numpy())\n",
    "\n",
    "    mae = mean_absolute_error(true_vals, preds)\n",
    "    return mae\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import copy\n",
    "\n",
    "def train(model, train_loader, val_loader, epochs=10, patience=3, save_path='best_model.pth'):\n",
    "    model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n",
    "\n",
    "    best_mae = float('inf')\n",
    "    best_model_state = None\n",
    "    best_optimizer_state = None\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\n🔁 Epoch {epoch + 1}/{epochs}\")\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for images, tabular, labels in train_loader:\n",
    "            images, tabular, labels = images.to(device), tabular.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, tabular).view(-1)\n",
    "            loss = criterion(outputs, labels.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        mae = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, tabular, labels in val_loader:\n",
    "                images, tabular, labels = images.to(device), tabular.to(device), labels.to(device)\n",
    "                outputs = model(images, tabular).view(-1)\n",
    "                val_loss += criterion(outputs, labels.view(-1)).item()\n",
    "                mae += torch.mean(torch.abs(outputs - labels)).item()\n",
    "\n",
    "        val_loss_avg = val_loss / len(val_loader)\n",
    "        val_mae = mae / len(val_loader)\n",
    "\n",
    "        print(f\"✅ Epoch {epoch + 1} Summary:\")\n",
    "        print(f\"   🧪 Avg Training Loss: {train_loss / len(train_loader):.4f}\")\n",
    "        print(f\"   🧪 Avg Validation Loss (MSE): {val_loss_avg:.4f}\")\n",
    "        print(f\"   📊 MAE: {val_mae:.4f}\")\n",
    "\n",
    "        # 🔽 Check for improvement\n",
    "        scheduler.step(val_loss_avg)\n",
    "\n",
    "        if val_mae < best_mae:\n",
    "            print(\"🌟 New best model found! Saving...\")\n",
    "            best_mae = val_mae\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            best_optimizer_state = copy.deepcopy(optimizer.state_dict())\n",
    "            torch.save({\n",
    "                'model_state_dict': best_model_state,\n",
    "                'optimizer_state_dict': best_optimizer_state,\n",
    "                'mae': best_mae,\n",
    "                'epoch': epoch + 1\n",
    "            }, save_path)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"⏳ No improvement. Patience: {patience_counter}/{patience}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(\"🛑 Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a846049f",
   "metadata": {},
   "source": [
    "**Cell 5: Run Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81bf4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, train_loader, val_loader, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a39da6",
   "metadata": {},
   "source": [
    "# Step 3: Testing Model with new Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac076fde",
   "metadata": {},
   "source": [
    "**Cell: Save val_df as clean_test_data.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d0358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the validation split as test CSV for prediction\n",
    "test_save_path = r\"C:\\Users\\yasha\\Downloads\\ProjectEXH02\\dataset\\clean_test_data.csv\"\n",
    "val_df.to_csv(test_save_path, index=False)\n",
    "\n",
    "print(f\"✅ clean_test_data.csv saved at:\\n{test_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7ed423",
   "metadata": {},
   "source": [
    "**Test Data Loading and Integrity Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d550cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "test_csv_path = r\"C:\\Users\\yasha\\Downloads\\ProjectEXH02\\dataset\\clean_test_data.csv\"\n",
    "test_df = pd.read_csv(test_csv_path)\n",
    "\n",
    "# Double-check for NaNs or infs before processing\n",
    "print(\"🧪 Checking for NaNs or Inf:\")\n",
    "print(test_df[['Age', 'Sex', 'SmokingStatus', 'Weeks']].isnull().sum())\n",
    "print(np.isinf(test_df[['Age', 'Sex', 'SmokingStatus', 'Weeks']]).sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedaeb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaNs with column mean\n",
    "tabular_features = ['Age', 'Sex', 'SmokingStatus', 'Weeks']\n",
    "test_df[tabular_features] = test_df[tabular_features].replace([np.inf, -np.inf], np.nan)\n",
    "test_df[tabular_features] = test_df[tabular_features].fillna(test_df[tabular_features].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49aa5fe6",
   "metadata": {},
   "source": [
    "**Feature Scaling of Tabular Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e42f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "X_test_tabular = scaler.transform(test_df[tabular_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8be9c6",
   "metadata": {},
   "source": [
    "**🧪 Creating Custom Test Dataset and DataLoader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e288a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "class FVCMixedDataset(Dataset):\n",
    "    def __init__(self, df, tabular_data, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tabular_data = tabular_data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row['png_path']).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        tabular = torch.tensor(self.tabular_data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(row['FVC'], dtype=torch.float32)  # Label used just for completeness\n",
    "\n",
    "        return image, tabular, label\n",
    "\n",
    "# Image transformations (for MobileNetV3-Large)\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# Dataset and loader\n",
    "test_dataset = FVCMixedDataset(test_df, X_test_tabular, transform=image_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca74d72",
   "metadata": {},
   "source": [
    "**Loading the Trained FVCNet Model for Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure FVCNet is defined above this cell\n",
    "\n",
    "# Initialize model and load weights\n",
    "model = FVCNet()\n",
    "checkpoint = torch.load('best_model.pth', map_location=device)\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"✅ Loaded best model with MAE: {checkpoint['mae']:.4f} from Epoch {checkpoint['epoch']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc59f0dd",
   "metadata": {},
   "source": [
    "**🔮 Making Predictions and Saving Final Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ab0dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, tabular_data, _ in test_loader:  # labels not needed for inference\n",
    "        images = images.to(device)\n",
    "        tabular_data = tabular_data.to(device)\n",
    "\n",
    "        outputs = model(images, tabular_data).view(-1)\n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "# Save predictions to CSV\n",
    "pred_df = test_df.copy()\n",
    "pred_df['Predicted_FVC'] = predictions\n",
    "pred_df.to_csv(\"fvc_predictions.csv\", index=False)\n",
    "print(\"✅ Predictions saved to fvc_predictions.csv\")\n",
    "\n",
    "# Save full model checkpoint\n",
    "save_path = \"final_model.pth\"\n",
    "checkpoint = {\n",
    "    'epoch': -1,  # Replace -1 with the correct epoch if available\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'loss': -1.0  # Replace with actual loss if tracked\n",
    "}\n",
    "\n",
    "# Save optimizer state only if defined\n",
    "if 'optimizer' in globals():\n",
    "    checkpoint['optimizer_state_dict'] = optimizer.state_dict()\n",
    "\n",
    "torch.save(checkpoint, save_path)\n",
    "print(f\"✅ Final model checkpoint saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c450c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28308b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class FVCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FVCNet, self).__init__()\n",
    "        \n",
    "        # Use MobileNetV3-Large for image branch\n",
    "        self.cnn = models.mobilenet_v3_large(pretrained=True)\n",
    "        \n",
    "        # Modify the classifier for the specific task\n",
    "        self.cnn.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.cnn.classifier[3].in_features, 128),  # Use the in_features of the last layer\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Tabular branch\n",
    "        self.tabular_net = nn.Sequential(\n",
    "            nn.Linear(4, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Combined head\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 + 16, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, image, tabular):\n",
    "        img_feat = self.cnn(image)\n",
    "        tab_feat = self.tabular_net(tabular)\n",
    "        combined = torch.cat((img_feat, tab_feat), dim=1)\n",
    "        # Use .view(-1) to ensure output is a 1D tensor (batch_size,)\n",
    "        return self.fc(combined).view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc4faa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_keys = set(checkpoint['model_state_dict'].keys())\n",
    "model_keys = set(model.state_dict().keys())\n",
    "\n",
    "print(\"Missing in checkpoint:\", model_keys - ckpt_keys)\n",
    "print(\"Unexpected in checkpoint:\", ckpt_keys - model_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c700f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "class FVCNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FVCNet, self).__init__()\n",
    "\n",
    "        # MobileNetV3-Large for image branch\n",
    "        self.cnn = models.mobilenet_v3_large(pretrained=True)\n",
    "\n",
    "        # Rebuild the classifier as it was during training\n",
    "        self.cnn.classifier[3] = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(self.cnn.classifier[3].in_features, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Tabular branch\n",
    "        self.tabular_net = nn.Sequential(\n",
    "            nn.Linear(4, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Combined head for final predictions\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 + 16, 64),  # fc.0\n",
    "            nn.ReLU(),                # fc.1\n",
    "            nn.Dropout(0.3),          # fc.2\n",
    "            nn.Linear(64, 1)          # fc.3\n",
    "        )\n",
    "\n",
    "    def forward(self, image, tabular):\n",
    "        img_feat = self.cnn(image)\n",
    "        tab_feat = self.tabular_net(tabular)\n",
    "        combined = torch.cat((img_feat, tab_feat), dim=1)\n",
    "        return self.fc(combined).view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18e22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FVCNet()\n",
    "checkpoint = torch.load(\"final_model.pth\", map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])  # strict=True (default)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "print(\"✅ Final model loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca830e16",
   "metadata": {},
   "source": [
    "# Step 3: Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14a139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84b14b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions with ground truth\n",
    "df = pd.read_csv(r\"C:\\Users\\yasha\\Downloads\\ProjectEXH02\\fvc_predictions.csv\")\n",
    "\n",
    "# Ensure proper types\n",
    "df['FVC'] = df['FVC'].astype(float)\n",
    "df['Predicted_FVC'] = df['Predicted_FVC'].astype(float)\n",
    "\n",
    "# Extract ground truth and predictions\n",
    "y_true = df['FVC'].values\n",
    "y_pred = df['Predicted_FVC'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd7f351",
   "metadata": {},
   "source": [
    "**📊 Model Performance Evaluation Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6dd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = mean_squared_error(y_true, y_pred) ** 0.5  # manually take square root\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(\"📊 Evaluation Metrics:\")\n",
    "print(f\"✅ MAE  : {mae:.2f}\")\n",
    "print(f\"✅ RMSE : {rmse:.2f}\")\n",
    "print(f\"✅ R²    : {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b093953a",
   "metadata": {},
   "source": [
    "# **Scatter Plot (Ground Truth vs Predicted)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e843ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_true, y_pred, alpha=0.6, color='teal', label=\"Predictions\")\n",
    "plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--', label=\"Perfect Prediction\")\n",
    "plt.xlabel(\"True FVC\")\n",
    "plt.ylabel(\"Predicted FVC\")\n",
    "plt.title(\"True vs Predicted FVC\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5a35e2",
   "metadata": {},
   "source": [
    "**This scatter plot compares the true FVC values (from the dataset) with the predicted FVC values (from the model).**\n",
    "\n",
    "•\t**Teal dots represent the model's predictions.**\n",
    "\n",
    "•\t**The red dashed line represents perfect predictions (i.e., Predicted FVC = True FVC).**\n",
    "\n",
    "•\t**The closer the dots are to this line, the better the model’s performance.**\n",
    "\n",
    "•\t**A strong linear alignment along this line indicates high accuracy and good generalization by the model.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb946095",
   "metadata": {},
   "source": [
    "# **Residual Plot (Prediction Error)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f63596",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_true - y_pred\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.6, color='purple')\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.xlabel(\"Predicted FVC\")\n",
    "plt.ylabel(\"Residual (True - Predicted)\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aece98d5",
   "metadata": {},
   "source": [
    "**This plot shows the residuals against the predicted FVC values:**\n",
    "\n",
    "•\t**Each point represents how far off a prediction was from the actual value.**\n",
    "\n",
    "•\t**The red dashed line at 0 indicates perfect prediction.**\n",
    "\n",
    "\n",
    "•\t**Ideally, the residuals should be randomly scattered around the line, without a visible pattern.**\n",
    "\n",
    "•\t**If patterns emerge (e.g., funnel shape), it may indicate heteroscedasticity or model limitations at certain FVC levels.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a1662",
   "metadata": {},
   "source": [
    "**Saving Final Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a403bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the model weights (state_dict)\n",
    "torch.save(model.state_dict(), 'final_ipf_detection_weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f2374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load predictions with ground truth from CSV\n",
    "df = pd.read_csv(r\"C:\\Users\\yasha\\Downloads\\ProjectEXH02\\fvc_predictions.csv\")\n",
    "\n",
    "# Extract values\n",
    "y_true = df['FVC'].values\n",
    "y_pred = df['Predicted_FVC'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f347e4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Metrics\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "# Tabular summary\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['MAE', 'RMSE', 'R² Score'],\n",
    "    'Value': [mae, rmse, r2]\n",
    "})\n",
    "\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f079c1d",
   "metadata": {},
   "source": [
    "# 📊 Evaluation Metrics Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ce72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Bar chart of metrics\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(metrics_df['Metric'], metrics_df['Value'], color=['skyblue', 'salmon', 'lightgreen'])\n",
    "plt.title('Evaluation Metrics Bar Chart')\n",
    "plt.ylabel('Value')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9520fb2",
   "metadata": {},
   "source": [
    "**This bar chart visualizes the main evaluation metrics used to assess the model:**\n",
    "\n",
    "•\t**MAE (Mean Absolute Error): Average absolute difference between predicted and true FVC values. Lower is better.**\n",
    "\n",
    "•\t**RMSE (Root Mean Squared Error): Similar to MAE but gives more weight to larger errors. Lower is better.**\n",
    "\n",
    "\n",
    "•\t**R² Score (Coefficient of Determination): Indicates how well the model explains the variance in the target variable. Closer to 1 means better performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bec22a",
   "metadata": {},
   "source": [
    "# Error Distribution (Residuals Histogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764b2ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals (errors)\n",
    "residuals = y_true - y_pred\n",
    "\n",
    "# Plot histogram of residuals\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(residuals, bins=30, color='purple', edgecolor='black', alpha=0.7)\n",
    "plt.title('Error Distribution (Residuals Histogram)')\n",
    "plt.xlabel('Residual (True - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16080828",
   "metadata": {},
   "source": [
    "**This histogram shows the distribution of residuals (i.e., True FVC - Predicted FVC):**\n",
    "•\t**The histogram is centered around 0, meaning the model is not biased towards overpredicting or underpredicting.**\n",
    "\n",
    "•\t**A symmetric and narrow bell shape indicates that most predictions are close to the true values.**\n",
    "\n",
    "•\t**Wider tails or skewness would suggest outliers or consistent bias.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1e4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['MAE', 'RMSE', 'R² Score'],\n",
    "    'Value': [mae, rmse, r2]\n",
    "})\n",
    "\n",
    "# Save as CSV\n",
    "metrics_df.to_csv(\"mobilenet_evaluation_metrics.csv\", index=False)\n",
    "print(\"📁 Metrics table saved as 'mobilenet_evaluation_metrics.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff73695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "metrics = ['MAE', 'RMSE', 'R² Score']\n",
    "values = [mae, rmse, r2]\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(metrics, values, color=['skyblue', 'salmon', 'lightgreen'])\n",
    "\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2.0, yval + 1, f'{yval:.2f}', ha='center', va='bottom')\n",
    "\n",
    "plt.title('Model Evaluation Metrics')\n",
    "plt.ylabel('Score')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"bar_chart_metrics.png\")\n",
    "plt.close()\n",
    "print(\"📊 Bar chart saved as 'bar_chart_metrics.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f17d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "residuals = y_true - y_pred\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(residuals, bins=30, color='orange', edgecolor='black', alpha=0.7)\n",
    "plt.title('Error Distribution (Residuals)')\n",
    "plt.xlabel('Residual')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"residual_histogram.png\")\n",
    "plt.close()\n",
    "print(\"📈 Residual histogram saved as 'residual_histogram.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b7868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_true, y_pred, alpha=0.6, color='mediumseagreen', edgecolor='k')\n",
    "plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], 'r--')  # Perfect prediction line\n",
    "plt.title('Actual vs Predicted FVC')\n",
    "plt.xlabel('Actual FVC')\n",
    "plt.ylabel('Predicted FVC')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"scatter_actual_vs_predicted.png\")\n",
    "plt.close()\n",
    "print(\"📍 Scatter plot saved as 'scatter_actual_vs_predicted.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b157b4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save only the model weights (state_dict) one last time if needed\n",
    "torch.save(model.state_dict(), 'lastly_saved_ipf_detection.pth')\n",
    "print(\"✅ Final model weights saved to 'lastly_saved_ipf_detection.pth'\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
